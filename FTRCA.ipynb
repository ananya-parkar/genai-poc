{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "524ae3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import configparser\n",
    "import snowflake.connector\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb4423b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ananya.Mehta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:196: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v4 of SentenceTransformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "SNOWFLAKE_CONFIG = {\n",
    "    \"user\": config[\"snowflake\"][\"user\"],\n",
    "    \"password\": config[\"snowflake\"][\"password\"],\n",
    "    \"account\": config[\"snowflake\"][\"account\"],\n",
    "    \"warehouse\": config[\"snowflake\"][\"warehouse\"],\n",
    "    \"database\": config[\"snowflake\"][\"database\"],\n",
    "    \"schema\": config[\"snowflake\"][\"schema\"],\n",
    "}\n",
    "\n",
    "# Hugging Face API configuration for Mistral v2\n",
    "API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "API_KEY = config[\"huggingface\"][\"api_key\"]\n",
    "\n",
    "# Load the model with authentication (if required)\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', use_auth_token=API_KEY)\n",
    "\n",
    "HEADERS = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7811b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create AI Solutions Table in Snowflake\n",
    "def create_ai_solutions_table():\n",
    "    conn = snowflake.connector.connect(**SNOWFLAKE_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS AI_SOLUTIONS (\n",
    "        number STRING PRIMARY KEY,\n",
    "        incident_subject STRING,\n",
    "        priority STRING,\n",
    "        business_service STRING,\n",
    "        opened TIMESTAMP,\n",
    "        short_description STRING,\n",
    "        ai_generated_Solution STRING,\n",
    "        root_cause_analysis STRING\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f20ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Fetch Latest Email Alert from Snowflake\n",
    "def fetch_latest_email_alert():\n",
    "    conn = snowflake.connector.connect(**SNOWFLAKE_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    query = \"\"\"\n",
    "        SELECT subject, INCIDENT_ID, impact_level, affected_service, timestamp, description\n",
    "        FROM cleaned_alerts\n",
    "        ORDER BY timestamp DESC\n",
    "        LIMIT 1;\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    latest_alert = cursor.fetchone()\n",
    "    column_names = [desc[0].lower() for desc in cursor.description]\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return dict(zip(column_names, latest_alert)) if latest_alert else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee155c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_root_cause_analysis(alert_data, similar_solution=None):\n",
    "    if not alert_data:\n",
    "        return \"No new alerts found.\"\n",
    "    \n",
    "    formatted_alert = f\"\"\"\n",
    "    Incident ID: {alert_data['incident_id']}\n",
    "    Subject: {alert_data['subject']}\n",
    "    Impact Level: {alert_data['impact_level']}\n",
    "    Affected Service: {alert_data['affected_service']}\n",
    "    Timestamp: {alert_data['timestamp']}\n",
    "    Description: {alert_data['description']}\n",
    "    \"\"\"\n",
    "    \n",
    "    if similar_solution:\n",
    "        prompt = f\"\"\"\n",
    "        Analyze this alert and its similar solution to provide a detailed root cause analysis:\\n\\n{formatted_alert}\\n\\nSimilar Solution:\\n{similar_solution}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"\n",
    "        Analyze this alert and provide a detailed root cause analysis:\\n\\n{formatted_alert}\n",
    "        \"\"\"\n",
    "    \n",
    "    data = {\"inputs\": prompt}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_URL, headers=HEADERS, json=data)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        \n",
    "        if isinstance(result, list) and result:\n",
    "            rca_details = result[0].get(\"generated_text\", \"\")\n",
    "            if rca_details:  # Only print if analysis exists\n",
    "                # Find the start of the root cause analysis section\n",
    "                start_index = rca_details.find(\"Root Cause Analysis:\")\n",
    "                print(f\"Root Cause Analysis for Incident {alert_data['incident_id']}:\")\n",
    "                if start_index != -1:\n",
    "                    # Extract the root cause analysis section\n",
    "                    rca_section = rca_details[start_index + len(\"Root Cause Analysis:\"):].strip()\n",
    "                    \n",
    "                    # Remove leading/trailing whitespace and empty lines\n",
    "                    rca_lines = [line.strip() for line in rca_section.splitlines() if line.strip()]\n",
    "                    \n",
    "                    # Format RCA details in bullets\n",
    "                    formatted_rca = \"\\n\".join(f\"* {line}\" for line in rca_lines)\n",
    "                    print(formatted_rca)\n",
    "                else:\n",
    "                    print(\"No root cause analysis found.\")\n",
    "            return rca_details\n",
    "        \n",
    "        return \"\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e18530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Store AI Solution in Snowflake\n",
    "def store_rca_results(alert_data, root_cause_analysis):\n",
    "    conn = snowflake.connector.connect(**SNOWFLAKE_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Ensure this matches your RCA_RESULTS table schema\n",
    "    query = \"\"\"\n",
    "        INSERT INTO RCA_RESULTS (\n",
    "            NUMBER, CONFIGURATION_ITEM, INCIDENT_SUBJECT, BUSINESS_SERVICE, OPENED,\n",
    "            ALERT_TIME, STATE, CLOSED_BY, CLOSED, PRIORITY,\n",
    "            TICKET_OPENED_BY, INCIDENT_DURATION, ACTION_TO_RESOLVE_INCIDENT,\n",
    "            RESOLUTION_TYPE, RESOLVED_BY, SHORT_DESCRIPTION,\n",
    "            NEXT_STEPS, RCA\n",
    "        )\n",
    "        VALUES (\n",
    "            %s, %s, %s, %s, %s,\n",
    "            %s, %s, %s, %s, %s,\n",
    "            %s, %s, %s, %s, %s,\n",
    "            %s, %s, %s\n",
    "        )\n",
    "    \"\"\"\n",
    "    \n",
    "    # Map alert_data fields to RCA_RESULTS columns\n",
    "    values = (\n",
    "        alert_data.get('incident_id', None),  # NUMBER\n",
    "        alert_data.get('configuration_item', None),  # CONFIGURATION_ITEM\n",
    "        alert_data.get('subject', None),  # INCIDENT_SUBJECT\n",
    "        alert_data.get('business_service', None),  # BUSINESS_SERVICE\n",
    "        alert_data.get('opened', None),  # OPENED\n",
    "        alert_data.get('alert_time', None),  # ALERT_TIME\n",
    "        alert_data.get('state', None),  # STATE\n",
    "        alert_data.get('closed_by', None),  # CLOSED_BY\n",
    "        alert_data.get('closed', None),  # CLOSED\n",
    "        alert_data.get('priority', None),  # PRIORITY\n",
    "        alert_data.get('ticket_opened_by', None),  # TICKET_OPENED_BY\n",
    "        alert_data.get('incident_duration', None),  # INCIDENT_DURATION\n",
    "        alert_data.get('action_to_resolve_incident', None),  # ACTION_TO_RESOLVE_INCIDENT\n",
    "        alert_data.get('resolution_type', None),  # RESOLUTION_TYPE\n",
    "        alert_data.get('resolved_by', None),  # RESOLVED_BY\n",
    "        alert_data.get('short_description', None),  # SHORT_DESCRIPTION\n",
    "        alert_data.get('next_steps', None),  # NEXT_STEPS\n",
    "        root_cause_analysis  # RCA (Root Cause Analysis)\n",
    "    )\n",
    "    \n",
    "    cursor.execute(query, values)\n",
    "    conn.commit()\n",
    "    cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cde44f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Load Existing Embeddings from Snowflake\n",
    "def load_existing_embeddings():\n",
    "    conn = snowflake.connector.connect(**SNOWFLAKE_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    query = \"\"\"\n",
    "        SELECT number, short_description, ai_generated_Solution\n",
    "        FROM AI_SOLUTIONS;\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    cursor.close()\n",
    "\n",
    "    incident_ids = [row[0] for row in rows]\n",
    "    descriptions = [row[1] for row in rows]\n",
    "    solutions = [row[2] for row in rows]\n",
    "\n",
    "    return incident_ids, descriptions, solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f4b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Build FAISS Index and Perform Similarity Check\n",
    "def build_faiss_index(descriptions):\n",
    "   embeddings = embedding_model.encode(descriptions, convert_to_numpy=True)\n",
    "   dim = embeddings.shape[1]\n",
    "   index = faiss.IndexFlatL2(dim)\n",
    "   index.add(embeddings)\n",
    "   return index\n",
    "\n",
    "def check_for_similar_alert(new_description, index, descriptions, incident_ids, solutions, threshold=0.85):\n",
    "   new_embedding = embedding_model.encode([new_description], convert_to_numpy=True)\n",
    "   D, I = index.search(new_embedding, k=1)\n",
    "   similarity = 1 / (1 + D[0][0])  # Convert L2 to similarity\n",
    "   \n",
    "   if similarity >= threshold:\n",
    "       match_idx = I[0][0]\n",
    "       return solutions[match_idx]\n",
    "   \n",
    "   return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0db25be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Cause Analysis for Incident INC-20250407-002:\n",
      "* Both incidents describe unauthorized access attempts, but they differ in their contexts and methods.\n",
      "* The first incident is about an attempt to access the primary database cluster directly through its network interface. In this case, an unrecognized IP address attempted multiple failed login attempts, infringing on the basic security principle that only authorized entities should be allowed to access the database.\n",
      "* The second incident is about an API request attempt, which failed due to an Access Denied error. The request was trying to create a new user with the \"admin\" role, which likely required permissions beyond those granted to the requester.\n",
      "* Although these incidents do not appear to be directly related, they highlight the importance of maintenance, updates, and strict access control measures.\n",
      "* In the first incident, attacks against the database network may indicate vulnerabilities that attackers can exploit, such as outdated software, misconfigured firewalls, or lack of authentication mechanisms. Implementing best practices like keeping software updated, applying security patches, and using strong passwords can help secure the database against unauthorized access from IP addresses or direct connections.\n",
      "* In the second incident, it is essential to ensure that access to APIs is granted only to authorized users. This can be achieved by implementing authentication and authorization mechanisms, as well as using techniques like rate limiting to prevent brute force attacks on API endpoints. Additionally, API usage logs and access control policies should be monitored to detect potential abuse or unauthorized activity.\n",
      "* In summary, both incidents revolve around the theme of unauthorized access and can be prevented by employing strong access control measures and implementing best security practices. A holistic approach to security, encompassing both the database infrastructure and API access, can help avoid potential vulnerabilities and protect sensitive data from unauthorized access.\n"
     ]
    }
   ],
   "source": [
    "# Main Workflow Execution\n",
    "create_ai_solutions_table()\n",
    "\n",
    "latest_alert = fetch_latest_email_alert()\n",
    "\n",
    "if latest_alert:\n",
    "   incident_ids, descriptions, solutions = load_existing_embeddings()\n",
    "\n",
    "   if descriptions:\n",
    "       index = build_faiss_index(descriptions)\n",
    "       matched_solution = check_for_similar_alert(\n",
    "           latest_alert[\"description\"], index, descriptions, incident_ids, solutions\n",
    "       )\n",
    "   else:\n",
    "       matched_solution = None\n",
    "\n",
    "   if matched_solution:\n",
    "       root_cause_analysis = generate_root_cause_analysis(latest_alert, matched_solution)\n",
    "       store_rca_results(latest_alert, root_cause_analysis)\n",
    "   else:\n",
    "       generated_solution = generate_root_cause_analysis(latest_alert)  # Generate RCA without similar solution\n",
    "       store_rca_results(latest_alert, generated_solution)  # Store RCA in new table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
